{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment2_Starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deangarcia/NLP/blob/main/NLP_Assignment2_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdlZYgLKwBMk"
      },
      "source": [
        "In this assignment, you will familiarize yourself with:\n",
        "\n",
        "    spaCy\n",
        "    numpy\n",
        "    PyTorch\n",
        "\n",
        "to develop\n",
        "\n",
        "    Multiple sentiment analysis models\n",
        "\n",
        "to be able to\n",
        "\n",
        "    Predict whether a given review is positive or negative\n",
        "\n",
        "Before we begin, make sure your runtime is set to GPU -- \n",
        "\n",
        "Runtime > Change runtime type set to GPU\n",
        "\n",
        "First we will load in some data.\n",
        "\n",
        "Provided is code that will download a file and rename it to reviews.tar.gz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPUCX7P0x4c7"
      },
      "source": [
        "Included is a vocabulary of all the words we can potentially see -- No '\\<UNK\\>' *here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_1Hn4muw4Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01b6ce3-69f7-46cc-983a-eb4a3a1c52fe"
      },
      "source": [
        "!head aclImdb/imdb.vocab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'aclImdb/imdb.vocab' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KAYND-Byigx"
      },
      "source": [
        "So, we have 12500 reviews for positive and negative classifications, and 50000 that are unlabeled.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtD78S4P0Rc9"
      },
      "source": [
        "Looking at the words in a review that don't show up in the vocab, we need to handle punctuation in a more delicate way (also, we will be making everything lower cased).  For this, we will turn to a standard modern NLP library spaCy.  spaCy is a library that handles a number of different low-level NLP tasks like tokenization, part-of-speech recognition, and named entity recognition.  For now, we will be focusing on the tokenization aspect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "positive_reviews = !ls -1 -d aclImdb/train/pos/*\n",
        "negative_reviews = !ls -1 -d aclImdb/train/neg/*\n",
        "unsupervised_reviews = !ls -1 -d aclImdb/train/unsup/*\n",
        "\n",
        "print(positive_reviews[:10])"
      ],
      "metadata": {
        "id": "mt4Q6RR2kprl",
        "outputId": "d8c3bdfd-1d74-4a8b-a9c1-646eb2858ecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-21 03:05:12--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  30.3MB/s    in 2.6s    \n",
            "\n",
            "2022-03-21 03:05:15 (30.3 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "['aclImdb/train/pos/0_9.txt', 'aclImdb/train/pos/10000_8.txt', 'aclImdb/train/pos/10001_10.txt', 'aclImdb/train/pos/10002_7.txt', 'aclImdb/train/pos/10003_8.txt', 'aclImdb/train/pos/10004_8.txt', 'aclImdb/train/pos/10005_7.txt', 'aclImdb/train/pos/10006_7.txt', 'aclImdb/train/pos/10007_7.txt', 'aclImdb/train/pos/10008_7.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "positive_reviews = !ls -1 -d aclImdb/train/pos/*\n",
        "negative_reviews = !ls -1 -d aclImdb/train/neg/*\n",
        "unsupervised_reviews = !ls -1 -d aclImdb/train/unsup/*\n",
        "\n",
        "vocabulary = set()\n",
        "array_review = []\n",
        "\n",
        "with open('./aclImdb/imdb.vocab') as vocab_file:\n",
        "  for word in vocab_file:\n",
        "    vocabulary.add(word.rstrip())\n",
        "\n",
        "with open(positive_reviews[0]) as review:\n",
        "  for line in review:\n",
        "    for word in line.rstrip().split(' '):\n",
        "      if word not in vocabulary:\n",
        "        pass\n",
        "        \n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "# Create a Tokenizer with the default settings for English\n",
        "# including punctuation rules and exceptions\n",
        "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
        "counts = {}\n",
        "rev_count = 0\n",
        "for review in positive_reviews + negative_reviews:\n",
        "  array_review.append(rev_count)\n",
        "  rev_count = rev_count + 1\n",
        "  with open(review) as review:\n",
        "    for line in review:\n",
        "      for word in tokenizer(line.rstrip().lower()):\n",
        "        if word.text not in vocabulary:\n",
        "          pass\n",
        "        else:\n",
        "          counts[word.text] = counts.get(word.text,0) + 1\n",
        "\n",
        "# The whole vocabulary needs to be setup so the words that appear most often are at the beggining of the set\n",
        "# so we need this extra array to organize our vocabulary\n",
        "count2words = {}\n",
        "for word in counts:\n",
        "  count = counts[word]\n",
        "  if count not in count2words:\n",
        "    count2words[count] = []\n",
        "  count2words[count].append(word)\n",
        "\n",
        "running_total = 0\n",
        "vocabulary = []\n",
        "for count in reversed(sorted(count2words)):\n",
        "  running_total += len(count2words[count])\n",
        "  vocabulary += count2words[count]\n",
        "  if running_total > 10000:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni7dUSj2KDy6",
        "outputId": "5e80dc47-f729-44f0-8047-d93f7b24b4d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-21 03:05:33--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  34.7MB/s    in 2.3s    \n",
            "\n",
            "2022-03-21 03:05:35 (34.7 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOXa3Gd2aTRA"
      },
      "source": [
        "We can now tokenize our text and the things we ignore are *mostly* puncutation (most tokenizers will split contractions like I'm into I and 'm which happens here, but the original vocab doesn't expect -- we will just let that happen here)\n",
        "\n",
        "\n",
        "#Step 1\n",
        "\n",
        "Fill out the function below to:\n",
        "\n",
        "* Tokenize a document\n",
        "* Extract all n-grams and their counts of the given order\n",
        "\n",
        "* It's ok to utilize your work from the first assignment here (although use SpaCy and go to lower case)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
        "\n",
        "def get_n_grams(filename,n):\n",
        "  ngrams = {}\n",
        "  texts = []\n",
        "  test = []\n",
        "\n",
        "  filex = open(filename,'r')\n",
        "  tokens = tokenizer(filex.read())\n",
        "  for token in tokens:\n",
        "    test.append(token.lemma_.lower())\n",
        "  texts.append(test)\n",
        "  #Text is a list of lists\n",
        "  for text in texts:\n",
        "    # iterate through each list (-n + 1 because of the nested for loop we dont want to go out of range and len(array) doesnt take into account 0)\n",
        "    for i in range(len(text) - n + 1):\n",
        "      temp = [] \n",
        "      # now iterate through the list j values which is the length of n to save our string values into a tuple\n",
        "      for j in range(n):\n",
        "        temp.append(text[i+j])\n",
        "      tuple_temp = tuple(temp)\n",
        "      # save the tuple as a key at increment it by one if it exists already \n",
        "      if tuple_temp in ngrams.keys():\n",
        "        ngrams[tuple_temp] += 1\n",
        "      # or set it to one on the first occurence\n",
        "      else:\n",
        "        ngrams[tuple_temp] = 1\n",
        "\n",
        "  return ngrams\n"
      ],
      "metadata": {
        "id": "ekL1ZkdZne1x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRYAEI6EEsvz"
      },
      "source": [
        "We are going to use Stochastic Gradient Descent to learn the weights for our regression, and we will be utilizing the PyTorch library to do so"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2iPFoIij719"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nENMjMTDej3v"
      },
      "source": [
        "With the ability to extract out n-grams, we will now be constructing a linear classifier.  To do this, we will need to set up our data.  \n",
        "\n",
        "#Step 2\n",
        "\n",
        "* Make a $|D|\\times|unigrams|$ tensor (`torch.Tensor`) , `X_unigrams` that contains all of the unigram counts for the documents -- each row should be a document and each column should be a unigram -- each cell corresponding to the number of times the unigram corresponding to the column shows up in the document corresponding to the row  \n",
        "i.e., $X_{unigrams}[i,j] = $ Count of unigram $j$ in document $i$\n",
        "* Make a $|D|\\times1$ tensor, `Y` that contains the ratings for the documents -- we will say that a positive review has a rating of `1` and a negative review is `0`\n",
        "*In torch, if we want to use a GPU for the training we need to move the data to the GPU using `.to('cuda')`.  For this to work you will need to make sure you are using a GPU instance (Runtime > Change Runtime Type > Hardware Accelerator = GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAiUqVNwXb57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6683f04e-f288-4706-ffef-179ed7a4d6f6"
      },
      "source": [
        "n = 1\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") \n",
        "data = []\n",
        "ratings = []\n",
        "for filename in positive_reviews + negative_reviews:\n",
        "  substring = \"pos\"\n",
        "  rating_val = []\n",
        "  if substring in filename:\n",
        "    ratings.append(1)\n",
        "  else:\n",
        "    ratings.append(0)\n",
        "  row_data = []\n",
        "  gram = get_n_grams(filename, n)\n",
        "  for i in range(len(vocabulary)):\n",
        "    temp_list = []\n",
        "    for j in range(n):\n",
        "      temp_list.append(vocabulary[i])\n",
        "    cmp_tuple = tuple(temp_list)\n",
        "    if cmp_tuple in gram.keys():\n",
        "      row_data.append(gram[cmp_tuple])\n",
        "    else:\n",
        "      row_data.append(0)\n",
        "  data.append(row_data)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  X_unigrams = torch.FloatTensor(data).to(device)\n",
        "  y = torch.FloatTensor(ratings).to(device)\n",
        "  y = y.view(y.shape[0], 1)\n",
        "\n",
        "print(X_unigrams) # not sure if the data model is setup correctly here how would we do a bigram or trigram?\n",
        "print(y)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 9.,  1.,  4.,  ...,  0.,  0.,  0.],\n",
            "        [24.,  4., 17.,  ...,  0.,  0.,  0.],\n",
            "        [10.,  4.,  6.,  ...,  0.,  0.,  0.],\n",
            "        ...,\n",
            "        [12.,  8.,  7.,  ...,  0.,  0.,  0.],\n",
            "        [ 9.,  5., 12.,  ...,  0.,  0.,  0.],\n",
            "        [10.,  1.,  5.,  ...,  0.,  0.,  0.]], device='cuda:0')\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_unigrams[-500:])\n",
        "print(y[-500:])\n",
        "print(len(array_review))"
      ],
      "metadata": {
        "id": "TjbojQ6Nkff8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JecKqSs-JeYn"
      },
      "source": [
        "We will first construct a module that does what we want.  In torch you implement modules and you define the forward pass of the model (Torch uses autograd to automatically compute the backward pass based on the forward pass). \n",
        "\n",
        "#Step 3\n",
        "* Implement the linear regression using Torch\n",
        "* You will want to use a `torch.nn.Linear` layer -- The linear layer is essentially a matrix multiplication as shown in class  -- think about what the input dimension and output dimensions should be (how big is our input, how many things are we predicting)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAWNjtPfiFXz"
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.linear = nn.Linear(size , 1)\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = self.linear(X)\n",
        "    return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAMXe-LiK7uD"
      },
      "source": [
        "With the above model, we now need to actually train it.  We are going to use a pretty simple training regimen here.\n",
        "\n",
        "#Step 4 \n",
        "* Create the optimizer -- I recommend using the Adam optimizer (`optim.Adam`) -- optimizers take in the parameters that they are optimizing (`model.parameters`) and other hyperparameters like the learning rate (`lr=learning_rate`)\n",
        "* Loop for the number of `epochs` supplied to the training code -- this will be the number of passes over our data\n",
        "* In each epoch we will loop over the data in batches -- go from 0 up to the size of `X` in steps of size `batch_size`\n",
        "* Within each training step we will need to follow the steps of training a neural network:\n",
        " * Zero out the gradients in the optimizer (by default the gradients are kept around) by calling `.zero_grad()` on the optimizer\n",
        " * Get the current batch -- we can use *slicing* to get certain elements in our input and output.  E.g. `X[i:i+step_size,:]` would return a Tensor with elements from X from row i to row i+step_size and all of the columns\n",
        " * Run the model on the batch making sure to assign the result to a variable -- you can either call `.forward(...)` or more simply just call the model `(...)`\n",
        " * Calculate the loss of the output -- this is done by calling the `loss_criterion` with the predicted values and the true values as the first and second arguments respectively\n",
        " * Run the loss in the backward direction -- Call `.backward()` on the loss calcualted in the previous step\n",
        " * Step the optimizer -- Call `.step()` on the optimizer\n",
        " * You might want to do something like log the value of the loss -- this can be gotten by calling `.item()` on the loss calculated above -- perhaps do this every 5, 10, 50, 100, 500 epochs (your choice)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl_GpD5_iGPy"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "def train(X, Y, model, batch_size, epochs, learning_rate, loss_criterion):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# dont count first array in the D x UNigram  tensor \n",
        "  for epoch in range(epochs + 1):\n",
        "    i = 0\n",
        "    for step_size in range(int(len(Y)/batch_size)):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(X[i:i+step_size,:])\n",
        "      loss = loss_criterion(output, Y[i:i+step_size,:])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      i = i + batch_size\n",
        "    if epoch % 500 == 1:\n",
        "      print(f'epoch {epoch} / {epochs}, step {step_size} / {batch_size}, loss = {loss.item():.4f}')\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16a5m2YnMoZu"
      },
      "source": [
        "#Step 5\n",
        "* Construct your model \n",
        "* Just as with the data above, if you want to use a GPU we have to tell torch to move the model (and parameters to the gpu) so you need to call `.to('cuda')` (Note this does not change the original model, it returns a model on the gpu so you probably want to do something like `model = model.to('cuda')`\n",
        "* Call the above training code -- watch how the loss changes as the model trains -- experiment with different training hyperparameters -- learning rate and epoch -- see when the model hits a minima\n",
        "* For a linear regression, we are using Mean Square Error as our loss `torch.nn.MSELoss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFStqz95MgqQ",
        "outputId": "a7c68e9a-74b9-44a3-eecc-3d1c8b0dd9ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "# Why is my first array empty\n",
        "  linear_model = LinearRegression(len(vocabulary)).to(device)\n",
        "\n",
        "  # How many times do we pass the training data over the over network\n",
        "  epochs = 2500\n",
        "\n",
        "  #If the data is to big to pass at once due to computer limitations pass it in\n",
        "  #smaller batches\n",
        "  batch_size = 5000\n",
        "  # Whenever you do learning and i goes over the learning rate if it reaches a minima and starts going up again reduce learning rate\n",
        "  learning_rate = 0.001\n",
        "  loss_criterion = nn.MSELoss()\n",
        "  train(X_unigrams, y, linear_model, batch_size, epochs, learning_rate, loss_criterion)\n",
        "  predicted = linear_model(X_unigrams).cpu().detach().numpy()\n",
        "  plt.plot(array_review, predicted)\n",
        "  plt.plot(array_review, ratings)\n",
        "  plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 2500, step 4 / 5000, loss = 0.2286\n",
            "epoch 501 / 2500, step 4 / 5000, loss = 0.0001\n",
            "epoch 1001 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 1501 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 2001 / 2500, step 4 / 5000, loss = 0.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(array_review[12000:13000], predicted[12000:13000])\n",
        "plt.plot(array_review[12000:13000], ratings[12000:13000])\n",
        "# calculate mean square loss\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RdX7UQnOfM5T",
        "outputId": "2642d384-3273-4d70-b80d-12bea7bb0481"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_W6f7iLQJV3"
      },
      "source": [
        "\n",
        "#Step 6\n",
        "* Implement the class below -- you should have two linear weights  (Input -> Hidden), (Hidden -> Output)\n",
        "* In your forward, make sure you apply a nonlinear activation function after going from (Input -> Hidden) before (Hidden -> Output) -- you can choose the nonlinear activation (sigmoid, tanh, relu, leaky-relu are all fine)\n",
        "* Train the model\n",
        "\n",
        "###Question 2\n",
        "How does this model compare to the above model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFL8_XzJQa52"
      },
      "source": [
        "class NonLinearRegression(nn.Module):\n",
        "  def __init__(self, size, hidden_size):\n",
        "    super(NonLinearRegression, self).__init__()\n",
        "    self.non_linear = nn.Linear(size , hidden_size).to(device)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.non_linear_2 = nn.Linear(hidden_size , 1).to(device)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = self.non_linear(X).to(device)\n",
        "    out = self.relu(out).to(device)\n",
        "    out = self.non_linear_2(out).to(device)\n",
        "    out = self.sigmoid(out).to(device)\n",
        "    return out"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "hidden_size = ((len(vocabulary) * 2) / 3) + 1\n",
        "hidden_size = int(hidden_size)\n",
        "nonlinear_model = NonLinearRegression(len(vocabulary), hidden_size).to(device)\n",
        "\n",
        "epochs = 2500\n",
        "batch_size = 5000 # what is the purpose of the batches?\n",
        "learning_rate = 0.0001 # what does this variable do?\n",
        "loss_criterion = nn.MSELoss()\n",
        "train(X_unigrams, y, nonlinear_model, batch_size, epochs, learning_rate, loss_criterion)"
      ],
      "metadata": {
        "id": "38pJbqVmN2BY",
        "outputId": "20cdfcd0-babc-4f5d-876f-a0418f5c513b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 2500, step 4 / 5000, loss = 0.2326\n",
            "epoch 501 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 1001 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 1501 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 2001 / 2500, step 4 / 5000, loss = 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZRcvYJBaUtZ"
      },
      "source": [
        "Ok, we have a linear regression and a non-linear regression -- let's do a Logistic Regression and non-linear Logistic regression now:\n",
        "#Step 7\n",
        "* Implement a standard logistic regression and a logistic regression with a hidden layer and non-linear activation\n",
        "* These should be very similar to above except they should have `torch.Sigmoid` applied to the output\n",
        "* Note, `MSELoss` is no longer applicable here -- we need to use Binary Cross Entropy Loss `torch.nn.BCELoss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRHAMOm9a12l"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.logistic = nn.Linear(size, 1)\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = torch.sigmoid(self.logistic(X))\n",
        "    return out\n",
        "\n",
        "\n",
        "class LogisticANN(nn.Module):\n",
        "  def __init__(self, size, hidden_size):\n",
        "    super(LogisticANN, self).__init__()\n",
        "    self.non_linear = nn.Linear(size , hidden_size).to(device)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.non_linear_2 = nn.Linear(hidden_size , 1).to(device)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = self.non_linear(X).to(device)\n",
        "    out = self.relu(out).to(device)\n",
        "    out = self.non_linear_2(out).to(device)\n",
        "    out = self.sigmoid(out).to(device)\n",
        "    return out"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "logistic_reg_model = LogisticRegression(len(vocabulary)).to(device)\n",
        "\n",
        "epochs = 2500\n",
        "batch_size = 5000 # what is the purpose of the batches?\n",
        "learning_rate = 0.001 # what does this variable do?\n",
        "loss_criterion = nn.BCELoss()\n",
        "train(X_unigrams, y, logistic_reg_model, batch_size, epochs, learning_rate, loss_criterion)\n",
        "\n",
        "hidden_size = ((len(vocabulary) * 2) / 3) + 1\n",
        "hidden_size = int(hidden_size)\n",
        "logisticann_model = LogisticANN(len(vocabulary), hidden_size).to(device)\n",
        "\n",
        "epochs = 2500\n",
        "batch_size = 5000 # what is the purpose of the batches?\n",
        "learning_rate = 0.001 # what does this variable do?\n",
        "loss_criterion = nn.BCELoss()\n",
        "train(X_unigrams, y, logisticann_model, batch_size, epochs, learning_rate, loss_criterion)"
      ],
      "metadata": {
        "id": "ZFv4TB47Tp9j",
        "outputId": "46ad38ba-48fe-424e-cfef-7ed870a4af37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 2500, step 4 / 5000, loss = 0.7702\n",
            "epoch 501 / 2500, step 4 / 5000, loss = 0.0005\n",
            "epoch 1001 / 2500, step 4 / 5000, loss = 0.0001\n",
            "epoch 1501 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 2001 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 1 / 2500, step 4 / 5000, loss = 0.0532\n",
            "epoch 501 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 1001 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 1501 / 2500, step 4 / 5000, loss = 0.0000\n",
            "epoch 2001 / 2500, step 4 / 5000, loss = 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "linear_predictions = linear_model(X_unigrams)\n",
        "non_linear_predictions = nonlinear_model(X_unigrams)\n",
        "logistic_predictions = logistic_reg_model(X_unigrams)\n",
        "ANN_predictions = logisticann_model(X_unigrams)\n",
        "\n",
        "loss_temp = nn.MSELoss()\n",
        "print('\\n Positive \\n')\n",
        "print(math.sqrt(loss_temp(linear_predictions[0:12500], y[0:12500]).item()))\n",
        "print(math.sqrt(loss_temp(non_linear_predictions[0:12500], y[0:12500]).item()))\n",
        "print(math.sqrt(loss_temp(logistic_predictions[0:12500], y[0:12500]).item()))\n",
        "print(math.sqrt(loss_temp(ANN_predictions[0:12500], y[0:12500]).item()))\n",
        "\n",
        "print('\\n Negative \\n')\n",
        "print(math.sqrt(loss_temp(linear_predictions[12500:], y[12500:]).item()))\n",
        "print(math.sqrt(loss_temp(non_linear_predictions[12500:], y[12500:]).item()))\n",
        "print(math.sqrt(loss_temp(logistic_predictions[12500:], y[12500:]).item()))\n",
        "print(math.sqrt(loss_temp(ANN_predictions[12500:], y[12500:]).item()))"
      ],
      "metadata": {
        "id": "X8dcpF7my7xx",
        "outputId": "6ccb91e8-b2e1-4433-f86f-bce6468adbb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Positive \n",
            "\n",
            "0.7045249776926907\n",
            "0.7766169692035182\n",
            "0.8132705702433165\n",
            "0.9223528771043374\n",
            "\n",
            " Negative \n",
            "\n",
            "0.4380610478916339\n",
            "0.24219239906770426\n",
            "0.2227832866794458\n",
            "0.1313350770733905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToziSarXRQAQ"
      },
      "source": [
        "# Step 8\n",
        "* This step is somewhat freeform -- just as it would be if you were doing exploratory resarch\n",
        "* Try doing some exploration of different models.  Some things you might try are:\n",
        " * different configurations of inputs (different order n-grams, combinations of n-grams)\n",
        " * different numbers and sizes of input layers\n",
        " * different non-linear activations\n",
        "\n",
        "* Normally, you should pick the model that does the best not on training data, but on the evaluation data.  Since this dataset doesn't come with an evaluation set, we will instead be using the test set as our evaluation set (this is obviously poor practice, and should not be done in the real world).  Or rather we will be using a portion of the test files as evaluation.\n",
        "\n",
        "* Pick a model architecture, train it, run it on the eval data \n",
        "* Do this multiple times, keep the best model \n",
        "\n",
        "#### Question 3:\n",
        "How do you pick the \"best\" model -- what metric do you want to use here?\n",
        "\n",
        "* As a note, there will be n-grams that show up in the evaluation and training sets that don't show up in the training data, you will have to be able to account for this (of course, ignoring is acceptable) but your code shouldn't fail\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5sC6wBUTJPG",
        "outputId": "79ca8359-5ef6-4860-863a-12e983669358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "positive_raw_test = !ls -1 -d aclImdb/test/pos/*\n",
        "negative_raw_test = !ls -1 -d aclImdb/test/neg/*\n",
        "\n",
        "positive_eval = positive_raw_test[:len(positive_raw_test)//4]\n",
        "negative_eval = negative_raw_test[:len(negative_raw_test)//4]\n",
        "positive_test = positive_raw_test[len(positive_raw_test)//4:]\n",
        "negative_test = negative_raw_test[len(negative_raw_test)//4:]\n",
        "\n",
        "\n",
        "print(len(positive_eval))\n",
        "print(len(negative_eval))\n",
        "print(len(positive_test))\n",
        "print(len(negative_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3125\n",
            "3125\n",
            "9375\n",
            "9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QKSuebJTPZP",
        "outputId": "7dbdedf3-5c1f-43ee-8694-ee720808fc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_correct = 0\n",
        "n_samples = 0\n",
        "n_test = 1\n",
        "for reviews_test in negative_reviews:\n",
        "  row_data_test = []\n",
        "  gram_test = get_n_grams(reviews_test, n)\n",
        "  for i in range(len(vocabulary)):\n",
        "    temp_list_test = []\n",
        "    for j in range(n):\n",
        "      temp_list_test.append(vocabulary[i])\n",
        "    cmp_tuple_test = tuple(temp_list_test)\n",
        "    if cmp_tuple_test in gram_test.keys():\n",
        "      row_data_test.append(gram_test[cmp_tuple_test])\n",
        "    else:\n",
        "      row_data_test.append(0)\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    test = torch.FloatTensor(row_data_test).to(device)\n",
        "  outputs_test = linear_model(test)\n",
        "  print(outputs_test)\n",
        "  _, predictions = torch.max(outputs_test, 0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3983], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.4392], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5049], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6822], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1739], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3390], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6165], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9546], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6699], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2581], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0071], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9599], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4394], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4215], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8162], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3522], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3490], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6701], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2338], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6076], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4387], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.0465], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6434], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6350], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5149], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.3691], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7010], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7130], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8717], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8156], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5156], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1432], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0969], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6044], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5189], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9912], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6954], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2189], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0246], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5080], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5235], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4389], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4599], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7532], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6692], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7465], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.9349], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8957], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6582], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4204], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3636], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7705], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4748], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5051], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.0541], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3669], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4931], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7454], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4630], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5521], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6042], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5072], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2317], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6746], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.3624], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5205], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3926], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3699], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4339], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.9539], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0768], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5911], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4955], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2945], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5154], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.9069], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5657], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1583], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2670], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9295], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6801], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8626], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7276], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2479], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6602], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9055], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3979], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4193], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2345], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5836], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4754], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5555], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5432], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2519], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6722], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4150], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3067], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3387], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0596], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8878], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5474], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6175], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9350], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8171], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3895], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0817], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6679], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4223], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7395], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5052], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7246], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5022], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1341], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9889], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8035], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0754], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1517], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3908], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9646], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8878], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9585], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0127], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9169], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3749], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7222], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5823], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6772], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6845], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4026], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9123], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1890], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5078], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7551], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5229], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2000], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5191], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3229], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6707], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6141], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4296], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5151], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2637], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0720], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0809], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4465], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7348], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0766], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6264], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7915], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6766], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5650], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6034], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6797], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6034], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4389], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0028], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.0833], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4618], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5361], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6596], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3583], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8221], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6276], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.3060], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9775], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5172], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0859], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4815], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4144], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7133], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5136], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1261], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5590], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7226], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6473], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.2408], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1890], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6924], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7983], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5172], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3893], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8297], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3852], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0212], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3864], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3675], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9058], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1015], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6674], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7442], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6528], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5453], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5442], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9977], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.3286], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3441], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5091], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4658], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4658], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4607], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5514], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4493], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6820], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4444], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5495], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6921], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2590], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9126], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5482], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4250], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1388], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2134], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4674], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8605], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7078], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6300], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5142], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2540], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2615], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3473], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1634], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3748], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1771], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5138], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3473], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7113], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7258], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6707], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5963], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8727], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7218], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3986], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3450], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8106], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2864], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1622], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5435], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5370], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6689], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2096], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7670], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1325], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7407], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4837], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.9684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5516], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6331], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5641], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0497], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6204], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9574], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6350], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5074], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5913], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3458], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3902], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6421], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8791], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4650], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4257], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1572], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5269], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4829], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3574], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5421], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6316], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9122], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0772], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7253], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7237], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4328], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8915], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3630], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7108], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6957], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3266], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4569], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2368], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5884], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3280], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1750], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1310], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4578], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5288], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4410], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6758], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9389], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7642], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2223], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6879], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3581], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6910], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6504], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3392], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5555], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4739], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5321], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1650], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0898], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0241], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0890], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5045], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4147], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6384], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6479], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8878], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6363], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6602], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3137], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6265], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3056], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.0064], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6413], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.1537], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5660], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4030], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4512], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6426], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4330], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4854], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4278], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4691], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9134], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4255], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3741], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6525], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.9051], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3674], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4063], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4781], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5030], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8145], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6861], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2320], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8524], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7602], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6907], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4813], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8917], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5819], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8940], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5449], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6078], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0608], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8761], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4961], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9118], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6118], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0099], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3530], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9722], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7136], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5033], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0482], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7664], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6866], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4582], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0524], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5380], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4577], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6165], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3724], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6083], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1495], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5502], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7789], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3647], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3755], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3346], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6341], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3449], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2732], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5343], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6846], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3539], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7064], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6256], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2459], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4030], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8781], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6100], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5322], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3265], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9170], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8129], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.0295], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6081], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4439], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2415], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9486], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9262], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3606], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4916], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5023], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8704], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8158], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8859], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6386], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4456], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2811], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4570], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8173], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6916], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4917], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9184], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6018], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9322], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2533], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6381], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4686], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3974], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9894], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2136], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6409], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2840], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4307], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9743], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2871], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6702], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4873], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1838], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7964], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8480], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6449], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6270], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1618], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8286], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3921], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7261], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3923], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5032], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7596], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3454], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9225], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0784], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4013], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3167], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5026], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5675], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4299], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7945], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2450], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3349], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5363], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3333], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7019], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6144], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5663], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8006], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7497], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6161], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2354], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5239], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6402], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1417], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5383], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2114], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3772], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5158], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8203], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1064], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3932], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7951], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3949], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6854], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7139], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3327], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5877], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5558], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5472], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8240], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6712], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4802], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4163], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6833], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8754], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3669], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2544], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2637], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4915], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4642], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7922], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3801], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6362], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5252], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6328], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8396], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2513], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7044], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2625], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7822], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.4427], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.4627], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6370], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9779], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1589], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5472], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7033], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4091], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6151], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9692], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5538], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9107], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3786], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1274], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4590], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3036], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2210], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8751], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7253], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5414], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5129], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6432], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5315], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5947], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5369], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7093], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4433], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6759], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7408], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2073], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2993], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7566], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2605], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4276], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6689], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6421], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4290], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8298], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4616], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-ebb5eb84e7b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtemp_list_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mtemp_list_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcmp_tuple_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_list_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VpPC8pGUrUE"
      },
      "source": [
        "## Bonus: Augment with unsupervised data\n",
        "* The dataset comes with more unsupervised data than supervised -- come up with a way to augment your training set with the unsupervised data, such that your model performance improves (to do this comparison keep model architecture the same, and compare the augmented data model vs the original on the evaluation set)"
      ]
    }
  ]
}