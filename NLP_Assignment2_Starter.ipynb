{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment2_Starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deangarcia/NLP/blob/main/NLP_Assignment2_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdlZYgLKwBMk"
      },
      "source": [
        "In this assignment, you will familiarize yourself with:\n",
        "\n",
        "    spaCy\n",
        "    numpy\n",
        "    PyTorch\n",
        "\n",
        "to develop\n",
        "\n",
        "    Multiple sentiment analysis models\n",
        "\n",
        "to be able to\n",
        "\n",
        "    Predict whether a given review is positive or negative\n",
        "\n",
        "Before we begin, make sure your runtime is set to GPU -- \n",
        "\n",
        "Runtime > Change runtime type set to GPU\n",
        "\n",
        "First we will load in some data.\n",
        "\n",
        "Provided is code that will download a file and rename it to reviews.tar.gz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPUCX7P0x4c7"
      },
      "source": [
        "Included is a vocabulary of all the words we can potentially see -- No '\\<UNK\\>' *here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_1Hn4muw4Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165201dc-6ab6-4443-e877-c086063be883"
      },
      "source": [
        "!head aclImdb/imdb.vocab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'aclImdb/imdb.vocab' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KAYND-Byigx"
      },
      "source": [
        "So, we have 12500 reviews for positive and negative classifications, and 50000 that are unlabeled.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtD78S4P0Rc9"
      },
      "source": [
        "Looking at the words in a review that don't show up in the vocab, we need to handle punctuation in a more delicate way (also, we will be making everything lower cased).  For this, we will turn to a standard modern NLP library spaCy.  spaCy is a library that handles a number of different low-level NLP tasks like tokenization, part-of-speech recognition, and named entity recognition.  For now, we will be focusing on the tokenization aspect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "positive_reviews = !ls -1 -d aclImdb/train/pos/*\n",
        "negative_reviews = !ls -1 -d aclImdb/train/neg/*\n",
        "unsupervised_reviews = !ls -1 -d aclImdb/train/unsup/*\n",
        "\n",
        "print(positive_reviews[:10])"
      ],
      "metadata": {
        "id": "mt4Q6RR2kprl",
        "outputId": "e4c10ad8-66b2-4d40-c8b0-f9fca657e323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-25 01:44:51--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  18.1MB/s    in 7.6s    \n",
            "\n",
            "2022-03-25 01:44:59 (10.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "['aclImdb/train/pos/0_9.txt', 'aclImdb/train/pos/10000_8.txt', 'aclImdb/train/pos/10001_10.txt', 'aclImdb/train/pos/10002_7.txt', 'aclImdb/train/pos/10003_8.txt', 'aclImdb/train/pos/10004_8.txt', 'aclImdb/train/pos/10005_7.txt', 'aclImdb/train/pos/10006_7.txt', 'aclImdb/train/pos/10007_7.txt', 'aclImdb/train/pos/10008_7.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "positive_reviews = !ls -1 -d aclImdb/train/pos/*\n",
        "negative_reviews = !ls -1 -d aclImdb/train/neg/*\n",
        "unsupervised_reviews = !ls -1 -d aclImdb/train/unsup/*\n",
        "\n",
        "vocabulary = set()\n",
        "array_review = []\n",
        "\n",
        "with open('./aclImdb/imdb.vocab') as vocab_file:\n",
        "  for word in vocab_file:\n",
        "    vocabulary.add(word.rstrip())\n",
        "\n",
        "with open(positive_reviews[0]) as review:\n",
        "  for line in review:\n",
        "    for word in line.rstrip().split(' '):\n",
        "      if word not in vocabulary:\n",
        "        pass\n",
        "        \n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "# Create a Tokenizer with the default settings for English\n",
        "# including punctuation rules and exceptions\n",
        "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
        "counts = {}\n",
        "rev_count = 0\n",
        "for review in positive_reviews + negative_reviews:\n",
        "  array_review.append(rev_count)\n",
        "  rev_count = rev_count + 1\n",
        "  with open(review) as review:\n",
        "    for line in review:\n",
        "      for word in tokenizer(line.rstrip().lower()):\n",
        "        if word.text not in vocabulary:\n",
        "          pass\n",
        "        else:\n",
        "          counts[word.text] = counts.get(word.text,0) + 1\n",
        "\n",
        "# The whole vocabulary needs to be setup so the words that appear most often are at the beggining of the set\n",
        "# so we need this extra array to organize our vocabulary\n",
        "count2words = {}\n",
        "for word in counts:\n",
        "  count = counts[word]\n",
        "  if count not in count2words:\n",
        "    count2words[count] = []\n",
        "  count2words[count].append(word)\n",
        "\n",
        "running_total = 0\n",
        "vocabulary = []\n",
        "for count in reversed(sorted(count2words)):\n",
        "  running_total += len(count2words[count])\n",
        "  vocabulary += count2words[count]\n",
        "  if running_total > 10000:\n",
        "    break"
      ],
      "metadata": {
        "id": "ni7dUSj2KDy6",
        "outputId": "d395c306-baaa-4844-fc42-9c774c1838b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-25 01:45:22--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  18.9MB/s    in 7.6s    \n",
            "\n",
            "2022-03-25 01:45:30 (10.6 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOXa3Gd2aTRA"
      },
      "source": [
        "We can now tokenize our text and the things we ignore are *mostly* puncutation (most tokenizers will split contractions like I'm into I and 'm which happens here, but the original vocab doesn't expect -- we will just let that happen here)\n",
        "\n",
        "\n",
        "#Step 1\n",
        "\n",
        "Fill out the function below to:\n",
        "\n",
        "* Tokenize a document\n",
        "* Extract all n-grams and their counts of the given order\n",
        "\n",
        "* It's ok to utilize your work from the first assignment here (although use SpaCy and go to lower case)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
        "\n",
        "def get_n_grams(filename,n):\n",
        "  ngrams = {}\n",
        "  texts = []\n",
        "  test = []\n",
        "\n",
        "  filex = open(filename,'r')\n",
        "  tokens = tokenizer(filex.read())\n",
        "  for token in tokens:\n",
        "    test.append(token.lemma_.lower())\n",
        "  texts.append(test)\n",
        "  #Text is a list of lists\n",
        "  for text in texts:\n",
        "    # iterate through each list (-n + 1 because of the nested for loop we dont want to go out of range and len(array) doesnt take into account 0)\n",
        "    for i in range(len(text) - n + 1):\n",
        "      temp = [] \n",
        "      # now iterate through the list j values which is the length of n to save our string values into a tuple\n",
        "      for j in range(n):\n",
        "        temp.append(text[i+j])\n",
        "      tuple_temp = tuple(temp)\n",
        "      # save the tuple as a key at increment it by one if it exists already \n",
        "      if tuple_temp in ngrams.keys():\n",
        "        ngrams[tuple_temp] += 1\n",
        "      # or set it to one on the first occurence\n",
        "      else:\n",
        "        ngrams[tuple_temp] = 1\n",
        "\n",
        "  return ngrams\n"
      ],
      "metadata": {
        "id": "ekL1ZkdZne1x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRYAEI6EEsvz"
      },
      "source": [
        "We are going to use Stochastic Gradient Descent to learn the weights for our regression, and we will be utilizing the PyTorch library to do so"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2iPFoIij719"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nENMjMTDej3v"
      },
      "source": [
        "With the ability to extract out n-grams, we will now be constructing a linear classifier.  To do this, we will need to set up our data.  \n",
        "\n",
        "#Step 2\n",
        "\n",
        "* Make a $|D|\\times|unigrams|$ tensor (`torch.Tensor`) , `X_unigrams` that contains all of the unigram counts for the documents -- each row should be a document and each column should be a unigram -- each cell corresponding to the number of times the unigram corresponding to the column shows up in the document corresponding to the row  \n",
        "i.e., $X_{unigrams}[i,j] = $ Count of unigram $j$ in document $i$\n",
        "* Make a $|D|\\times1$ tensor, `Y` that contains the ratings for the documents -- we will say that a positive review has a rating of `1` and a negative review is `0`\n",
        "*In torch, if we want to use a GPU for the training we need to move the data to the GPU using `.to('cuda')`.  For this to work you will need to make sure you are using a GPU instance (Runtime > Change Runtime Type > Hardware Accelerator = GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAiUqVNwXb57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85552184-0dc1-4662-ddac-89bc45c9aaae"
      },
      "source": [
        "n = 1\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") \n",
        "data = []\n",
        "ratings = []\n",
        "for filename in positive_reviews + negative_reviews:\n",
        "  substring = \"pos\"\n",
        "  rating_val = []\n",
        "  if substring in filename:\n",
        "    ratings.append(1)\n",
        "  else:\n",
        "    ratings.append(0)\n",
        "  row_data = []\n",
        "  gram = get_n_grams(filename, n)\n",
        "  for i in range(len(vocabulary)):\n",
        "    temp_list = []\n",
        "    for j in range(n):\n",
        "      temp_list.append(vocabulary[i])\n",
        "    cmp_tuple = tuple(temp_list)\n",
        "    if cmp_tuple in gram.keys():\n",
        "      row_data.append(gram[cmp_tuple])\n",
        "    else:\n",
        "      row_data.append(0)\n",
        "  data.append(row_data)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  X_unigrams = torch.FloatTensor(data).to(device)\n",
        "  y = torch.FloatTensor(ratings).to(device)\n",
        "  y = y.view(y.shape[0], 1)\n",
        "\n",
        "print(X_unigrams) # not sure if the data model is setup correctly here how would we do a bigram or trigram?\n",
        "print(y)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 9.,  1.,  4.,  ...,  0.,  0.,  0.],\n",
            "        [24.,  4., 17.,  ...,  0.,  0.,  0.],\n",
            "        [10.,  4.,  6.,  ...,  0.,  0.,  0.],\n",
            "        ...,\n",
            "        [12.,  8.,  7.,  ...,  0.,  0.,  0.],\n",
            "        [ 9.,  5., 12.,  ...,  0.,  0.,  0.],\n",
            "        [10.,  1.,  5.,  ...,  0.,  0.,  0.]], device='cuda:0')\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_unigrams[-500:])\n",
        "print(y[-500:])\n",
        "print(len(array_review))"
      ],
      "metadata": {
        "id": "TjbojQ6Nkff8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JecKqSs-JeYn"
      },
      "source": [
        "We will first construct a module that does what we want.  In torch you implement modules and you define the forward pass of the model (Torch uses autograd to automatically compute the backward pass based on the forward pass). \n",
        "\n",
        "#Step 3\n",
        "* Implement the linear regression using Torch\n",
        "* You will want to use a `torch.nn.Linear` layer -- The linear layer is essentially a matrix multiplication as shown in class  -- think about what the input dimension and output dimensions should be (how big is our input, how many things are we predicting)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAWNjtPfiFXz"
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.linear = nn.Linear(size , 1)\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = self.linear(X)\n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAMXe-LiK7uD"
      },
      "source": [
        "With the above model, we now need to actually train it.  We are going to use a pretty simple training regimen here.\n",
        "\n",
        "#Step 4 \n",
        "* Create the optimizer -- I recommend using the Adam optimizer (`optim.Adam`) -- optimizers take in the parameters that they are optimizing (`model.parameters`) and other hyperparameters like the learning rate (`lr=learning_rate`)\n",
        "* Loop for the number of `epochs` supplied to the training code -- this will be the number of passes over our data\n",
        "* In each epoch we will loop over the data in batches -- go from 0 up to the size of `X` in steps of size `batch_size`\n",
        "* Within each training step we will need to follow the steps of training a neural network:\n",
        " * Zero out the gradients in the optimizer (by default the gradients are kept around) by calling `.zero_grad()` on the optimizer\n",
        " * Get the current batch -- we can use *slicing* to get certain elements in our input and output.  E.g. `X[i:i+step_size,:]` would return a Tensor with elements from X from row i to row i+step_size and all of the columns\n",
        " * Run the model on the batch making sure to assign the result to a variable -- you can either call `.forward(...)` or more simply just call the model `(...)`\n",
        " * Calculate the loss of the output -- this is done by calling the `loss_criterion` with the predicted values and the true values as the first and second arguments respectively\n",
        " * Run the loss in the backward direction -- Call `.backward()` on the loss calcualted in the previous step\n",
        " * Step the optimizer -- Call `.step()` on the optimizer\n",
        " * You might want to do something like log the value of the loss -- this can be gotten by calling `.item()` on the loss calculated above -- perhaps do this every 5, 10, 50, 100, 500 epochs (your choice)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl_GpD5_iGPy"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "def train(X, Y, model, batch_size, epochs, learning_rate, loss_criterion):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# dont count first array in the D x UNigram  tensor \n",
        "  for epoch in range(epochs + 1):\n",
        "    i = 0\n",
        "    for step_size in range(int(len(Y)/batch_size)):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(X[i:i+batch_size,:])\n",
        "      loss = loss_criterion(output, Y[i:i+batch_size,:])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      i = i + batch_size\n",
        "    if epoch % 500 == 1:\n",
        "      print(f'epoch {epoch} / {epochs}, step {step_size} / {batch_size}, loss = {loss.item():.4f}')\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16a5m2YnMoZu"
      },
      "source": [
        "#Step 5\n",
        "* Construct your model \n",
        "* Just as with the data above, if you want to use a GPU we have to tell torch to move the model (and parameters to the gpu) so you need to call `.to('cuda')` (Note this does not change the original model, it returns a model on the gpu so you probably want to do something like `model = model.to('cuda')`\n",
        "* Call the above training code -- watch how the loss changes as the model trains -- experiment with different training hyperparameters -- learning rate and epoch -- see when the model hits a minima\n",
        "* For a linear regression, we are using Mean Square Error as our loss `torch.nn.MSELoss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFStqz95MgqQ",
        "outputId": "28891a9a-535b-46bf-d48d-3f8c9d75aa70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "# Why is my first array empty\n",
        "  linear_model = LinearRegression(len(vocabulary)).to(device)\n",
        "\n",
        "  # How many times do we pass the training data over the over network\n",
        "  epochs = 2500\n",
        "\n",
        "  #If the data is to big to pass at once due to computer limitations pass it in\n",
        "  #smaller batches\n",
        "  batch_size = 5000\n",
        "  # Whenever you do learning and i goes over the learning rate if it reaches a minima and starts going up again reduce learning rate\n",
        "  learning_rate = 0.001\n",
        "  loss_criterion = nn.MSELoss()\n",
        "  train(X_unigrams, y, linear_model, batch_size, epochs, learning_rate, loss_criterion)\n",
        "  predicted = linear_model(X_unigrams).cpu().detach().numpy()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 2500, step 4 / 5000, loss = 0.2112\n",
            "epoch 501 / 2500, step 4 / 5000, loss = 0.0585\n",
            "epoch 1001 / 2500, step 4 / 5000, loss = 0.0631\n",
            "epoch 1501 / 2500, step 4 / 5000, loss = 0.0639\n",
            "epoch 2001 / 2500, step 4 / 5000, loss = 0.0641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_adjusted = []\n",
        "right_wrong = {\"right\": 0, \"wrong\": 0}\n",
        "for i in range(len(predicted)):\n",
        "  if predicted[i] >= 0.5:\n",
        "    predicted_adjusted.append(1)\n",
        "    if predicted_adjusted[i] == ratings[i]:\n",
        "      right_wrong[\"right\"] = right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      right_wrong[\"wrong\"] = right_wrong[\"wrong\"] + 1\n",
        "  else:\n",
        "    predicted_adjusted.append(0)\n",
        "    if predicted_adjusted[i] == ratings[i]:\n",
        "      right_wrong[\"right\"] = right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      right_wrong[\"wrong\"] = right_wrong[\"wrong\"] + 1\n",
        "\n",
        "\n",
        "print(\"Linear Right Percentage: %\", right_wrong[\"right\"]/len(predicted))\n",
        "print(\"Linear Wrong Percentage: %\", right_wrong[\"wrong\"]/len(predicted))\n",
        "plt.plot(array_review[12000:13000], predicted_adjusted[12000:13000])\n",
        "plt.plot(array_review[12000:13000], ratings[12000:13000])\n",
        "# calculate mean square loss\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "RdX7UQnOfM5T",
        "outputId": "1a678f3a-9772-4cf5-ab35-1cda2401afda"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Right Percentage: % 0.95972\n",
            "Linear Wrong Percentage: % 0.04028\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de7QeVX33v79zzYWQCzki5NJADbwGtAJnBdpSpCqaQBexoC1R1FbbvK8tvm8VrSgWMa2tgG+7XiuKtEWlF8PF6orLaOS1sOiiJnIQEkgwcohpcsIlF9NAEpKTk/PrHzPPOfM8z8wzey7PM7P3fD9rnXVm9uzZ13l+s2d/90VUFYQQQuynq+gEEEIIyQcadEIIcQQadEIIcQQadEIIcQQadEIIcYSeoiKeO3euLlq0qKjoCSHESh577LF9qjoQdq0wg75o0SIMDQ0VFT0hhFiJiPxn1DV2uRBCiCPQoBNCiCPQoBNCiCPQoBNCiCPQoBNCiCPEGnQRuUtE9ojIUxHXRUS+ICLDIrJZRM7PP5mEEELiMGmhfw3AshbXlwNY7P+tAvDl7MkihBCSlNhx6Kr6sIgsauFlBYC71VuHd4OIzBKR01T1+ZzSWMfTG9fj4JPrjfweODKK2dP6Qq+pAgePHsesqb117sfGxnHo2Bim93djSk83AODw6Bh6urrQ3+O9/w68chyzG+5rF68cPwEAmNrbHenn+Pg4jh4fR3eXoEswke4aYek9PHoCPV0ykacoDrxyHLOm9OKFl4/i1Bn96BIJ9TOttxtj44qXjnrHADDTj7NWplN6u3BiXHHyFM/95WNjmNrbjZ6u5jAnwj4yilnT+hDto95vX08XRsfGARHMmtrbdJ8CEPEPIvJ7yulnYunVH65zP3r8BL67+Xlcdf48SEgZhLFx+37Mmd6HxafOMPKfBzv2HcbIgVdw8eK5odcPHxvDA1tfxGkzp9Slbef+I9ix/zAuOat+vspPdh7AlJ5uLDn95LanvZ18+/HduGzJqZjeH23yDh0bww+ffhFjJxRXvP40DO85hLFxxRsWzDKK48S44puPjWDGlB5csGg2XjVjSl7JNyaPiUXzAOwKnI/4bk0GXURWwWvFY+HChakiO/izR7B0113mN+xPFQ0J42BB8XawDrtEgf3Awd+8FjPnTBq3z33vp/jaf+zA3Bn9eONZoZP0mvjdOzcAAHZ87oq2pDWMSz//UMs4/+zbT+FfH989cV7zd8ltD4bed9WX/qNleDbw+M4D+JN7nsBV583DX//uGyL9feJfn8R3Nj0HANg08l+4+0fe/B3TvN/z6C588ltPAgAWv+okPPCRN2ZMeXI6OlNUVe8EcCcADA4OptpZ46L3rAawOtbf5f/v37H1+Zfwl7/9OrzrwuaXx9mf+h6OjY3jjmsvwLJzXz3hvuiG704cP/PZ5XjxpaO4+JbJh/3LDz2LW77/Uyw/99X48rUXpMmCMYePjeGcT3tfI5tvfutEy7aRYJoBYNtfLEO/30r/5LeexL9s3IkPvek1uP6tZwMAnj/4Cn71r/4NQOuH9T3/sBH//sy+OrdG/7d+/6f40kPPht7/ycv/B1Zd8stN6btn1UWY2teNK7/4SMs03P/YCD563yYsnDMND//pb0amE5is7yCnntyPjZ98y8T5I8P78O6/3wgAePCjl+KMudPr/K+6ewinbbsbn+n9OnT8RN21PS8fBQAcOjrWMh1l54WXjhadhI5zZNSry7i8v3DwlYnjPS8dSxzPgSOjE8c7f3Ek8f15kMcol90AFgTO5/tuhRL3tsi6TxM3euocalBbYT6S1lHQO3fyIjaSh0FfC+C9/miXiwAcbFf/OSGEkGhiu1xE5BsALgUwV0RGAHwaQC8AqOodANYBuBzAMIAjAH6/XYlNQk22itKv4q7X/DQKYLVTQ10sE8E4kkQnAd/S8L/xelZal1/4RRExSsNk2s39tkqbRBwH3dguJzZjMsplZcx1BfDHuaUoJ9jl4g7FdLmMJ7uZkBLAmaKEEOIIzhv0uI/1Vte9roFk4eVJXddJgj6euq6akL6lPLuLWnWHRHZ3iVkacu/WCiuXBtT3RFGU2IjzBp0QQqqCswbdXBRt0cIMud8OUTR4LCFu+ZGmHExvmSjr3ERRCT0OhqEd/QYjJF+cNegURT1MBMWyw3HohJjhrEEnhJCq4bxBj/tcby2KNt+f5xjuJCTp2gjrRpI29bnEicrh7oaiaM5lHSoWG8IGO7EB5w06IemgBSf24axBl6aD8OstZzqKlEgUTTBsse5Y6v4nDSs+staictQVI6Ezd1E0PowoUbQT9U1IVpw16BRFPSiKJoknwLj95Uaqh7MGnRBCqobzBj32MzvGQ5Ff2vUzRRPcF+I3iyDYMq6E6ai5F9GFERRp42aKNrmzwU4swHmDTkgaXOiqItXDWYMeNxPUeGnWJlHUFxk7LIomu69ZAC1ipmjUpbAZuOFhNwu6SeKKErSDYTeGEWXGKYoSG3DWoFMU9XChpcmZooSY4axBJ4SQquGsQZeG/1HX43tcGmeK+v870eUSPE7b/YLmLqIkS/Gahh96LXKmaJl3LHJbFHUlH0kwzXOeZVNUMTtr0NtNFX8YVYI7FhEbcd6gZ22MthLW2k2YuJlPWJ0hbunitPenxSQ812eKupKPJJjmuVPDeduJswbdVBR1/flutyiafiSOud92iKJh8VMUJbbjrEEnhJCq4axBjxMv48apN/ozDTdP8hRF69w6NVM0yl3MvozCFhZLEldzPlt3YbUah06IDThr0NsNv8gdhxVMLMR5g56nmBh23k7S7ikaH1aH8hA5S9cs/jKJooTYgLMGnaKoB0VR8/jrRdH6YYtssBMbcNagE0JI1XDWoJuLombhTJyL2X15UL/ca7oIQ4XFPEXRFDsWebeUc6ZoZPiuf8oRJ3DWoLcbfoK7DeuX2AgNegxJ96VsF7mKosVqoh27vzm8+AApihKbcdagm4uibv+Ay7p8btGiaFi1t/LOFjuxAWcNOiGZoAUnFmJk0EVkmYhsE5FhEbkh5PpCEXlQRB4Xkc0icnn+SU1G3ExQc1E0fHWuTotkmZfPrXPLj9Y7FkUvdGU4Er1lOM0+m+OJ8hM5U1TdXpyLuE2sQReRbgC3A1gOYAmAlSKypMHbpwDcq6rnAbgGwJfyTmjZYAPObbg4F7ERkxb6UgDDqrpdVUcBrAGwosGPAjjZP54J4Ln8kpiNzA2rsoiiGZuI7drgwjTOOvdSzxQlxF5MDPo8ALsC5yO+W5CbAVwrIiMA1gH4UFhAIrJKRIZEZGjv3r0pkmsOZ4p6tH2maMoSTPJSKWKmaJKwCCkLeYmiKwF8TVXnA7gcwD+KSFPYqnqnqg6q6uDAwEBOURPSDrhjEbEPE4O+G8CCwPl83y3IBwDcCwCq+iMAUwDMzSOBaTGdKRq7p2i4JmqNSBY2U7Rzomj0PWbL59b+5yWKti4Db/lciqLEXkwM+qMAFovIGSLSB0/0XNvgZyeANwOAiLwWnkFvb59KwfAT3G10nBVM7CPWoKvqGIDrAKwH8DS80SxbRGS1iFzpe7sewB+KyCYA3wDwe1qSYQKZl8/NObyiKNNMUfM9HvNNKJfPJa7TY+JJVdfBEzuDbjcFjrcC+PV8k5YNzhT1aL8omvK+wpfPbU4ARVFiO5wpSkgIZV0ygZBWOGvQjUXRuHCadixKnaRCCJ8R2aFx6FECY6J5ovmJoiZhRJlx2+qdVBNnDbop/KFmI8/NqztJbOzcsYhYiPMGPfOyszmHVxT1m2V0KtKotBjeXshMUVtrmBCHDTpninqUd6aoud8yzBQlxAacNeiEZKEko24JSYSzBj0/UbT1edkJWz63c3Enc2/yV5uV24aZotFhcKYosRdnDbpxl4vjv1QXht+1pcslxHAHvTfeW5UGO79M7MZZg04IIVWjAgY95jM74Y5FRQ+3S0sxU/9b7FhkkIa8y7ouzoig2T4lNlMBg05ICrSay+eyx8VunDXo7RJFbWugh+8p2qmZosmvhHnLTRSN/Rrj8rnEbpw16ByH7lFWUZQ7FhGSP84adEIyUVELXs1cu4OzBl0a/kdeT7GAU5r7imKiy6VNU/9b7ljUYuq/bTsWuUIV31Omec6zbIoqZmcNerup4g8jDFfLoaxdVe2G49DtxnmDnnXiULOwZmcLrm7YYgFx1rkb31/EjkXp77UBV/KRhCIWgyuqmJ016KaiqOuyaK2lWbaGV/GLc7m9YxFb2tXEWYNOSBaqahCrmWt3cNag5yWKNs8UNbuvLEyKogG3HBPfUhSNHNMtiYTO/ETRGP9wRxSNeh9V8T1FUZTEUsUfRhjOlgNnihILcd6gZ22M2r58bhj2iKK5JcU4PNdnirqSjyRQFHUAzhT1oChqHr9TomjRCSCF4KxBJyQLthnwvKjq+HtXcNag57Y4V+O5ZU36cFG0oMQkjH9yYbF8RNHYpZThTss2apROFV9UFEUrhK0ThWyn6FKPe0lUdthiNbPtDM4b9KxLxTYafFs3uAjSqZdY5AYXhmVYhCha/KumvVSx/UJR1AEoinqUVRRNUvBlEEVtw6W8EHOcNeiEZKKi49CJ3Thr0KXpIOK6aTi1c8ua9GGiaOfijnA3FkVr//OfKRoVhistW84UnYSiaAMiskxEtonIsIjcEOHnd0Rkq4hsEZF/yTeZ7cM2A+0KZdciKIoSG+mJ8yAi3QBuB3AZgBEAj4rIWlXdGvCzGMAnAPy6qh4QkVe1K8FJyWo2aPDTk7nschdF4wN0ZS2XKKr4PFMUrWcpgGFV3a6qowDWAFjR4OcPAdyuqgcAQFX35JvM5JiLom4/4WUVRW2bKWobnCBUTUwM+jwAuwLnI75bkLMAnCUij4jIBhFZFhaQiKwSkSERGdq7d2+6FBPSEappEPkisJu8RNEeAIsBXApgJYC/E5FZjZ5U9U5VHVTVwYGBgZyiDmdypmjUWGjDcBrHoVv2zVqsKJptoau8Z4qaiaJuL85F3MbEoO8GsCBwPt93CzICYK2qHlfVnwP4GTwDX3r4Qy2Goos9aVdb2bqs4rAtvSQfTAz6owAWi8gZItIH4BoAaxv8fBte6xwiMhdeF8z2HNOZmrwNR9GGyCYi19ExfIsWs3yu/7+iFrGi2XaGWIOuqmMArgOwHsDTAO5V1S0islpErvS9rQewX0S2AngQwMdUdX+7Em2C+Z6iblNeUdTcWlMUJcSM2GGLAKCq6wCsa3C7KXCsAD7i/xFiP2V7A3aIaubaHZyfKZp1+dym+yzrcynlTNGE9+cniposn0tRlNiLswbdFP5Qi6HoYk8av20NdtvS206qVBbOG/S8Jw65PhEpT6JFUdP7c667BHuKVlcUrWa+XcFZg86Zoh7lFUXN/bZHFG1OQMmKKBOcIDRJlcrCWYNOSDaqYwSCVDPX7uCsQaco6lGkKBpVykl3LMpvT9H4MGjQiM04a9BNsc1Au0LRXV2uV3vZutiKpEpl4bxB50zR4sgsiuaXlATx+qLoeDV3LKqS8XMR5w06IVUkyi5X0WCbZrkyOxa5DLtcCqLgco+r9yqNjKijotl2BfcNOg12YWSeKcodi3KHDZhoqrJjkdMULc5VlaINi23r2ieFE4QmqVJZOG/QabCLI9JoGldJ3rN845n46VfICASpbFeTIzhv0AmpIhRFJ6EoWiEc//IuLaUv9ipaPlQ2287gvEGnwS6OaFG0zDsWuf3A8PcQDUVRB+DzXQyui5JFw5Z2gAqVhfMGnWajfBQ2U9QgxIkWekaLaOvICjtTTWo4b9AJqSQRltnS90wmTEfuUBR1AH75FwOLnZD8cd6gs6+2fJjPFC1ix6La/6xdLplubxuxSx6UNeEdgKJoiTHdsShp0dv2uBe5Y1GrKIvescg0DFvhBKFJqvSOctagE5KFrC1VW22IrekmHs4a9LbtWJTyvqIocseiyHHohomZqMOcdiyKC8Xbsci2Gg4n6n1UpdZqDdM8UxR1AHaxFwPX2CEkf5w36DQb5aOo5XNNIo4bh24+BK6cTeF4UbQz6SgjFEVLjKkomrTgbXveKYomiccdXMpLVqpUFs4adEKyENXCNu6PzTEtnYSjY+zGWYNOUdSjnKKo6f1S9z9pXM2iaOtwbKvbVmR9IbmEafcXRVEH4MQjQogrVMCg02CXDSuWz40URc0oa0s4tgxKmu5OUBlRVESWicg2ERkWkRta+LtaRFREBvNLYjrMZ4rmG27ZKKsomiwciqJJcSkvWalSWcQadBHpBnA7gOUAlgBYKSJLQvzNAPB/AGzMO5HthO33Yih7T5diPNzdtD/WUjNiZ6pJDZMW+lIAw6q6XVVHAawBsCLE358DuAXA0RzTlxqKoh5lFEWTFmJHZ4qqbTUcDmeKTsKZovXMA7ArcD7iu00gIucDWKCq320VkIisEpEhERnau3dv4sS2g7K3FF2FM0UJyZ/MoqiIdAH4awDXx/lV1TtVdVBVBwcGBrJGbQTNRvkwHraYuyhqsmNR7aCqy+d2Jh1lpCqi6G4ACwLn8323GjMAnAvgIRHZAeAiAGuLFkYpinpQFE0SjzvY2offHqpTFiYG/VEAi0XkDBHpA3ANgLW1i6p6UFXnquoiVV0EYAOAK1V1qC0pzhl++hcDu7pIp0nyzKV5PsvwTMcadFUdA3AdgPUAngZwr6puEZHVInJluxOYlklRNLyUKYp2Iu5k7s3+8p4pGh9G7Dh0Wxp7KUVRF1v2tTzH5l3Dj5PGAxT3TdBj4klV1wFY1+B2U4TfS7Mnq3OU4a1aRVjshOSP8zNFaTjKh/EGF4XMFPX/R7VwC9hBPk8oikZTFVHUSiiKelAUTRKPO7iUl6xUqSycNeik3HBRNNJpKIpaDGeKelgtikrNf+eWz53cUzRq6n9sUjx/lrYL7Uy1GUm+2LKKokXhrEE3pQxv1SrCYm8vZTAuZaFKZeG8Qec48/KRdIOL/CKO95LXsEVbjUhZ90IlZjhv0AmpIlFdPlW010WMTCrz4lxOQ3GuGFjshOSP8wadhqN8lHnHohqRe3Ka3m8eVUfhOPRoOA7dAWjvi4FfRu2lyoa5kSqVReUNOuk85qJozvEa+IkXRU37YytkRUhpoEEnxEGiXifJxmK78VIqYmNviqIFwS9/QogrVN6gk/JSzI5F4v+nKFo1KIoSQkpJHt0lrhh3V7qOTKi8QedM0s5j3hLKt27MRNHaQeT6uUbYakNsXYOGeFTeoBPiIpHvoySiaD5JsQaKog5AUZQQ4gqVN+ik85R5pmjs8rnGfS5m3joNRdFoKIoSQpzFFTHRkWwYUXmDzh6XzlPcTFHzYYvEPbhjESEVJauoWPRokbTp14hjmzHdVzd4PeuORRRFi6IEb1VCCMkDGnTSccz3FM15HLqRKFo7yDhTtKTN23hRtKQJ7wAURQkhpSSPLh9XbHvWfNj0kqu8QedM0c5j2vIuomYoiroLRVFCqkrWTaJzTEoa8hFFi85FPtTynFYUTbMxOEXRgijDW5UQQvKg8gaddB5zUTTneI3C85fP1WwzRcva78qZotFQFCWElJI87LIrxj1rNmwqBiODLiLLRGSbiAyLyA0h1z8iIltFZLOI/FBEfin/pLYH9rh0nqK6ucxmihJXabcoWgZiDbqIdAO4HcByAEsArBSRJQ3eHgcwqKqvB3A/gFvzTighZcAeUTStqFt0yvOnVhbpRdHkZVJmUXQpgGFV3a6qowDWAFgR9KCqD6rqEf90A4D5+SazfeQ9eYUQQorCxKDPA7ArcD7iu0XxAQDfC7sgIqtEZEhEhvbu3WueSuIURb1EkyyfG9nCNYyrrP3PFEWjyfpYBp8ZJ0RREbkWwCCA28Kuq+qdqjqoqoMDAwN5Rt0cV8bred9XFKYLE7Un7oz318YPG4QU5iNpnm2r21ZQFJ2kSqJoj4Gf3QAWBM7n+251iMhbANwI4I2qeiyf5LUfdrgQUg0oino8CmCxiJwhIn0ArgGwNuhBRM4D8BUAV6rqnvyTmZy4+khbX7bVc21kRxEPaNYoa2k2GZ0S5qMxzybPRK3LRSJ2LDJtthY9y5IzRQNwpugkqjoG4DoA6wE8DeBeVd0iIqtF5Erf220ATgJwn4g8ISJrI4IjhBDSJky6XKCq6wCsa3C7KXD8lpzT1TFs/bQiyTERY2stq6yiaFkbtxRFo8ksigbDyhZUapydKUpR1IOiaIL4knkvOVw+t0bWriObup6cNeimcPlcQqoBRVGLoSjqQVHUPD1BUbSxeWq6BOuEfzNvbSO9KKqBYzfg8rmEEEKsgwbdtiY3SU2SmaJp7rUBV/KRhri8B69nLSeKooSUiOguC9P10HNMTAqiok/W7eBGp8vkyKUYfym6WerjKb67qvIGvcotFkKIW1TeoJPqkGQcOhpmik4OoTSj6KFuaRvXZRD28ibrh0YaUbQoaNAJIcQRKm/Q2eNCglAUdReKooRUldQ7/iTz1y6iunwSjUMvQRdCHpjOlo4ch266MXjEcSepvEHnjkWEEFeovEEnJIzGVllyUbRY8hBFC89ETnRKFC3DJw0NOiGEOELlDTo7XEgQiqLuQlGUkKoSKYqazhQt5zj0JMkqeix9XmSdKZqmm42iKCGElARbX2aVN+hV/gQlzUQtn5s4nJLaA+5YFE3mHYsCZccuF0JIbuTRwnTGuKfIiK2LlFXeoHPHIhLEnp8uSQp3LCKkqmTcsahouGPRJJ0TRYsvOxp0QghpwNaXWeUNuq2fVqQ9TI5Dr/9J154T43U9SmoRKIpGQ1GUEOIsNomBrUi1+1DG3YuKggadkABRM0WJ/VAUJaSiNLZOk4qiRU9MSS+Khh/bTK0uU+8palzniW/JHRp0Qghpws7XGQ06IQGifsa2foI34ko+0pBkca6ssiZFUULKRNTiXNlu7xhpu3yCXU22zpZsJGVJBI7sGdlEg05IAIqixGZo0AkJJasoWiz5iKJu7C9qWneRM0VTCOGlFkVFZJmIbBORYRG5IeR6v4jc41/fKCKL8k4oIYR0ClvfX7EGXUS6AdwOYDmAJQBWisiSBm8fAHBAVV8D4G8A3JJ3QgnpDNyxyFUS7ViUNa6M96elx8DPUgDDqrodAERkDYAVALYG/KwAcLN/fD+AL4qIaIFKypRe713VFVGL0/q6cWxsPHG43V1eeH09dvRW1dJZS3cS+nu6Y/30dEeHmybOILW6q9VlK8L8TOmNT3+Q/oD/RU98Hjs23zFx/pETig/3KbofEux42CBfCvygz3u+dqz+eKJ0ZKEWZ+9dXdgRksybx8aBvsnzWtom7vtq/X01951/0bk85M0bxxU/6FNgJ7BjdfSz9NlA2ch24OP+8cH/24WDBvH8zrji6r5Jk7dj9cci/e6/4E9wwRV/YJL8RJgY9HkAdgXORwBcGOVHVcdE5CCAUwDsC3oSkVUAVgHAwoULUybZjNvffT7W/HgXXnvajNDr9/2vX8MPn36x6Ud/9/uX4p6hXXjH+fMn3L6w8jzMntYLAHjza0/FBy/9Zaz6jTPbl/gAf/feQYzHvBe/+cFfwzMvvoxZ03qbXjQfvuws9HQJ3nnBgjr3v115HmZO7W0Z7ueufh2++shJWH7uafjwPU/g8+/8lSY/77pwIV44eBRvWDALz+w5hO9seg4DM/rR19OFS84aADBZpmefOmOiHAHgr656Hc5+dXj9AMD82VNx/WVn4e3nzWuZTmCyvmdP68XaTc/h4sUDuPr85vs+9razMWtaeL5XX3kOvjKzFxu2X4W+o/uaru87NIq5J/WF3BnOy0fH0NfdhX6DF1JeHB9THDl+AjOnhv+0VYH9h0fR39NVl7bjJxRHjo1hZkPZHD52Al0imNpnRwMmin2HRnHK9L6WrfRa2QDA3JP68MroCYwrML3fvGGw79AougSYNbUPXS2KrO+kOcZhJkHiGtEi8g4Ay1T1D/zz9wC4UFWvC/h5yvcz4p8/6/tp/lX4DA4O6tDQUA5ZIISQ6iAij6nqYNg1k9fubgDB5t183y3Uj4j0AJgJYH/ypBJCCEmLiUF/FMBiETlDRPoAXANgbYOftQDe5x+/A8C/Fdl/TgghVSS2D93vE78OwHoA3QDuUtUtIrIawJCqrgXwDwD+UUSGAfwCntEnhBDSQUxEUajqOgDrGtxuChwfBfDOfJNGCCEkCXZL14QQQiagQSeEEEegQSeEEEegQSeEEEeInVjUtohF9gL4z5S3z0XDLNQKwDxXA+a5GmTJ8y+p6kDYhcIMehZEZChqppSrMM/VgHmuBu3KM7tcCCHEEWjQCSHEEWw16HcWnYACYJ6rAfNcDdqSZyv70AkhhDRjawudEEJIAzTohBDiCIUadBG5S0T2+Btk1NxuE5GfishmEfmWiMwKXPuEvxH1NhF5W8A9dBNrf8nfjb77Pf7yv4WSJM8icpmIPCYiT/r/3xS45wLffVhEviDi7cUiInNE5AERecb/P7vzuawnaT371xeKyCER+WjAzYp6TvFcv15EfiQiW/w6neK7O1nHItIrIl/38/a0iHwicI8VdeynKSzPf+7n9wkR+YGInO67i1+Hw/718wP3vM+vy2dE5H0B99D6b4mqFvYH4BIA5wN4KuD2VgA9/vEtAG7xj5cA2ASgH8AZAJ6Ft5xvt398JrwdATcBWOLfcy+Aa/zjOwB8sMj8psjzeQBO94/PBbA7cM+PAVwEbz/a7wFY7rvfCuAG//iGWli25Dlw/X4A9wH4qH9uTT0nrOMeAJsB/Ip/fgqAbpfrGMC7AKzxj6cB2AFgkU113CLPJweO/zeAO/zjy/06FL9ON/rucwBs9//P9o9nt6r/Vn+FttBV9WF466cH3X6gqmP+6QZ4OyQB3kbUa1T1mKr+HMAwvA2sJzaxVtVRAGsArPDfZm+CZxgA4OsA3t7WDBmQJM+q+riqPue7bwEwVUT6ReQ0eA/OBvVq/m5M5m0FvLwCFuYZAETk7QB+Di/PNayp54T5fSuAzaq6yfe3X1VPOF7HCmC6eLubTQUwCuAlWFTHQGSeXwqcToeXV8Crs7vVYwOAWX4dvw3AA6r6C1U9AOABAMti6j+SsvehvwytHCsAAALaSURBVB/emwkI36x6Xgv3UwD8V+CBqrmXnWCeg1wN4CeqegxePkYC14J5O1VVn/ePXwBwarsSmiMTeRaRkwB8HMBnGvy4VM/BOj4LgIrIehH5iYj8qe/ubB3DM8yHATwPYCeAz6vqL+BIHYvIZ0VkF4B3A6jtG5HUfrWq/0hKa9BF5EYAYwD+uei0dIqoPIvIOfA+Wf9nkvD8N3upx6WG5PlmAH+jqocKS1QbCclvD4CL4f34Lwbw2yLyZtPwLK3jpQBOADgdXvfp9SJyZkHJyx1VvVFVF8DL73WdjNtox6JOIyK/B+C3ALzZf2CB1ptVh7nvh/dZ0+O/2cM2ty4NEXmGiMwH8C0A71XVZ33n3Qh0UaA+by+KyGmq+rz/2ban7YlPSUSeLwTwDhG5FcAsAOMichTAY7C8niPyOwLgYVXd5/tZB69f9p/gbh2/C8D3VfU4gD0i8giAQXgtVavruIF/hrfT26cRbb92A7i0wf0htP6NR1MCYWER6kWFZQC2Ahho8HcO6kXR7fBElB7/+AxMCinn+Pfch3oh5Y+Kzm/CPM/y83NVSBiNgsnlvvttqBfMbi06v0ny3HDPzZgURa2q5wR1PBvAT+CJgz0A/j+AK1yuY3hdal/1j6f7fl5vWx1H5Hlx4PhDAO73j69AvSj6Y999Djy9aLb/93MAc1rVf8v0FFwY34DXj3YcXkvlA/DEzl0AnvD/7gj4vxGeCr4NAcUXnoL8M//ajQH3M/1CGfYfiP4SPADGeQbwKXh9jU8E/l7lXxsE8JSf5y9ictbvKQB+COAZ3zjMsSnPDffdDN+g21TPKZ7ra+EJwE8hYJxdrWMAJ/n1tAWeMf+YbXXcIs/f9OtsM4DvAJjn+xUAt/v5ehLAYCCc9/v5Ggbw+3H13+qPU/8JIcQRSiuKEkIISQYNOiGEOAINOiGEOAINOiGEOAINOiGEOAINOiGEOAINOiGEOMJ/AyyDbnmBDxonAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_W6f7iLQJV3"
      },
      "source": [
        "\n",
        "#Step 6\n",
        "* Implement the class below -- you should have two linear weights  (Input -> Hidden), (Hidden -> Output)\n",
        "* In your forward, make sure you apply a nonlinear activation function after going from (Input -> Hidden) before (Hidden -> Output) -- you can choose the nonlinear activation (sigmoid, tanh, relu, leaky-relu are all fine)\n",
        "* Train the model\n",
        "\n",
        "###Question 2\n",
        "How does this model compare to the above model?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 1\n",
        "b = 100\n",
        "c = 0\n",
        "for _ in range(100):\n",
        "  b -= 1\n",
        "print(a is b)"
      ],
      "metadata": {
        "id": "pwtdQGHV_TEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFL8_XzJQa52"
      },
      "source": [
        "class NonLinearRegression(nn.Module):\n",
        "  def __init__(self, size, hidden_size):\n",
        "    super(NonLinearRegression, self).__init__()\n",
        "    self.non_linear = nn.Linear(size , hidden_size).to(device)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.non_linear_2 = nn.Linear(hidden_size , 1).to(device)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = self.non_linear(X).to(device)\n",
        "    out = self.relu(out).to(device)\n",
        "    out = self.non_linear_2(out).to(device)\n",
        "    out = self.sigmoid(out).to(device)\n",
        "    return out"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "hidden_size = ((len(vocabulary) * 2) / 3) + 1\n",
        "hidden_size = int(hidden_size)\n",
        "nonlinear_model = NonLinearRegression(len(vocabulary), hidden_size).to(device)\n",
        "\n",
        "epochs = 2500\n",
        "batch_size = 5000 # what is the purpose of the batches?\n",
        "learning_rate = 0.001 # what does this variable do?\n",
        "loss_criterion = nn.MSELoss()\n",
        "train(X_unigrams, y, nonlinear_model, batch_size, epochs, learning_rate, loss_criterion)"
      ],
      "metadata": {
        "id": "38pJbqVmN2BY",
        "outputId": "2a9bfb52-8dd6-4224-d4c0-3618327656f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-e5d8dcb30c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnonlinear_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNonLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-f4ef339aac6b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, hidden_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNonLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linear_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_lin_predicted = nonlinear_model(X_unigrams).cpu().detach().numpy()\n",
        "\n",
        "non_lin_predicted_adjusted = []\n",
        "non_lin_right_wrong = {\"right\": 0, \"wrong\": 0}\n",
        "for i in range(len(non_lin_predicted)):\n",
        "  if non_lin_predicted[i] >= 0.5:\n",
        "    non_lin_predicted_adjusted.append(1)\n",
        "    if non_lin_predicted_adjusted[i] is ratings[i]:\n",
        "      non_lin_right_wrong[\"right\"] = non_lin_right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      non_lin_right_wrong[\"wrong\"] = non_lin_right_wrong[\"wrong\"] + 1\n",
        "  else:\n",
        "    non_lin_predicted_adjusted.append(0)\n",
        "    if non_lin_predicted_adjusted[i] is ratings[i]:\n",
        "      non_lin_right_wrong[\"right\"] = non_lin_right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      non_lin_right_wrong[\"wrong\"] = non_lin_right_wrong[\"wrong\"] + 1\n",
        "\n",
        "\n",
        "print(\"Non Linear Correct Right Percentage: %\", non_lin_right_wrong[\"right\"]/len(non_lin_predicted))\n",
        "print(\"Non Linear Correct Wrong Percentage: %\", non_lin_right_wrong[\"wrong\"]/len(non_lin_predicted))\n",
        "plt.plot(array_review[12000:13000], non_lin_predicted_adjusted[12000:13000])\n",
        "plt.plot(array_review[12000:13000], ratings[12000:13000])\n",
        "# calculate mean square loss\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gtJAvhaB8Zdz",
        "outputId": "9316fc76-b965-4110-e554-02972772e091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non Linear Right Percentage: % 0.51576\n",
            "Non Linear Wrong Percentage: % 0.48424\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZRcvYJBaUtZ"
      },
      "source": [
        "Ok, we have a linear regression and a non-linear regression -- let's do a Logistic Regression and non-linear Logistic regression now:\n",
        "#Step 7\n",
        "* Implement a standard logistic regression and a logistic regression with a hidden layer and non-linear activation\n",
        "* These should be very similar to above except they should have `torch.Sigmoid` applied to the output\n",
        "* Note, `MSELoss` is no longer applicable here -- we need to use Binary Cross Entropy Loss `torch.nn.BCELoss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRHAMOm9a12l"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.logistic = nn.Linear(size, 1)\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = torch.sigmoid(self.logistic(X))\n",
        "    return out\n",
        "\n",
        "\n",
        "class LogisticANN(nn.Module):\n",
        "  def __init__(self, size, hidden_size):\n",
        "    super(LogisticANN, self).__init__()\n",
        "    self.non_linear = nn.Linear(size , hidden_size).to(device)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = self.non_linear(X).to(device)\n",
        "    out = self.relu(out).to(device)\n",
        "    out = self.sigmoid(out).to(device)\n",
        "    return out"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "logistic_reg_model = LogisticRegression(len(vocabulary)).to(device)\n",
        "\n",
        "epochs = 2500\n",
        "batch_size = 5000 # what is the purpose of the batches?\n",
        "learning_rate = 0.001 # what does this variable do?\n",
        "loss_criterion = nn.BCELoss()\n",
        "train(X_unigrams, y, logistic_reg_model, batch_size, epochs, learning_rate, loss_criterion)\n",
        "\n",
        "hidden_size = ((len(vocabulary) * 2) / 3) + 1\n",
        "hidden_size = int(hidden_size)\n",
        "logisticann_model = LogisticANN(len(vocabulary), hidden_size).to(device)\n",
        "\n",
        "epochs = 2500\n",
        "batch_size = 5000 # what is the purpose of the batches?\n",
        "learning_rate = 0.001 # what does this variable do?\n",
        "loss_criterion = nn.BCELoss()\n",
        "train(X_unigrams, y, logisticann_model, batch_size, epochs, learning_rate, loss_criterion)"
      ],
      "metadata": {
        "id": "ZFv4TB47Tp9j",
        "outputId": "d15d28e9-84c1-4981-b3a7-53cdec83be0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 2500, step 4 / 5000, loss = 0.8894\n",
            "epoch 501 / 2500, step 4 / 5000, loss = 0.1111\n",
            "epoch 1001 / 2500, step 4 / 5000, loss = 0.0601\n",
            "epoch 1501 / 2500, step 4 / 5000, loss = 0.0347\n",
            "epoch 2001 / 2500, step 4 / 5000, loss = 0.0202\n",
            "epoch 1 / 2500, step 4 / 5000, loss = 0.7210\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-31006564174a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m \u001b[0;31m# what does this variable do?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mloss_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_unigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogisticann_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-2f03ccd7501d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, model, batch_size, epochs, learning_rate, loss_criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_predicted = logistic_reg_model(X_unigrams).cpu().detach().numpy()\n",
        "\n",
        "logistic_predicted_adjusted = []\n",
        "logistic_right_wrong = {\"right\": 0, \"wrong\": 0}\n",
        "for i in range(len(logistic_predicted)):\n",
        "  if logistic_predicted[i] >= 0.5:\n",
        "    logistic_predicted_adjusted.append(1)\n",
        "    if logistic_predicted_adjusted[i] is ratings[i]:\n",
        "      logistic_right_wrong[\"right\"] = logistic_right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      logistic_right_wrong[\"wrong\"] = logistic_right_wrong[\"wrong\"] + 1\n",
        "  else:\n",
        "    logistic_predicted_adjusted.append(0)\n",
        "    if logistic_predicted_adjusted[i] is ratings[i]:\n",
        "      logistic_right_wrong[\"right\"] = logistic_right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      logistic_right_wrong[\"wrong\"] = logistic_right_wrong[\"wrong\"] + 1\n",
        "\n",
        "\n",
        "print(\"Non Linear Right Percentage: %\", logistic_right_wrong[\"right\"]/len(logistic_predicted))\n",
        "print(\"Non Linear Wrong Percentage: %\", logistic_right_wrong[\"wrong\"]/len(logistic_predicted))\n",
        "plt.plot(array_review[12000:13000], logistic_predicted_adjusted[12000:13000])\n",
        "plt.plot(array_review[12000:13000], ratings[12000:13000])\n",
        "# calculate mean square loss\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X8dcpF7my7xx",
        "outputId": "4f93f67b-dfd2-4cf1-b59d-c5d47df65098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non Linear Right Percentage: % 0.53116\n",
            "Non Linear Wrong Percentage: % 0.46884\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANN_predicted = logisticann_model(X_unigrams).cpu().detach().numpy()\n",
        "\n",
        "ANN_predicted_adjusted = []\n",
        "ANN_right_wrong = {\"right\": 0, \"wrong\": 0}\n",
        "for i in range(len(ANN_predicted)):\n",
        "  if ANN_predicted[i] >= 0.5:\n",
        "    ANN_predicted_adjusted.append(1)\n",
        "    if ANN_predicted_adjusted[i] is ratings[i]:\n",
        "      ANN_right_wrong[\"right\"] = ANN_right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      ANN_right_wrong[\"wrong\"] = ANN_right_wrong[\"wrong\"] + 1\n",
        "  else:\n",
        "    ANN_predicted_adjusted.append(0)\n",
        "    if ANN_predicted_adjusted[i] is ratings[i]:\n",
        "      ANN_right_wrong[\"right\"] = ANN_right_wrong[\"right\"] + 1\n",
        "    else:\n",
        "      ANN_right_wrong[\"wrong\"] = ANN_right_wrong[\"wrong\"] + 1\n",
        "\n",
        "\n",
        "print(\"Non Linear Right Percentage: %\", ANN_right_wrong[\"right\"]/len(ANN_predicted))\n",
        "print(\"Non Linear Wrong Percentage: %\", ANN_right_wrong[\"wrong\"]/len(ANN_predicted))\n",
        "plt.plot(array_review[12000:13000], ANN_predicted_adjusted[12000:13000])\n",
        "plt.plot(array_review[12000:13000], ratings[12000:13000])\n",
        "# calculate mean square loss\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "twtGPkKY96Ob",
        "outputId": "fe11dabd-d547-4ce1-d0ff-71ebb54feebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non Linear Right Percentage: % 0.50716\n",
            "Non Linear Wrong Percentage: % 0.49284\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToziSarXRQAQ"
      },
      "source": [
        "# Step 8\n",
        "* This step is somewhat freeform -- just as it would be if you were doing exploratory resarch\n",
        "* Try doing some exploration of different models.  Some things you might try are:\n",
        " * different configurations of inputs (different order n-grams, combinations of n-grams)\n",
        " * different numbers and sizes of input layers\n",
        " * different non-linear activations\n",
        "\n",
        "* Normally, you should pick the model that does the best not on training data, but on the evaluation data.  Since this dataset doesn't come with an evaluation set, we will instead be using the test set as our evaluation set (this is obviously poor practice, and should not be done in the real world).  Or rather we will be using a portion of the test files as evaluation.\n",
        "\n",
        "* Pick a model architecture, train it, run it on the eval data \n",
        "* Do this multiple times, keep the best model \n",
        "\n",
        "#### Question 3:\n",
        "How do you pick the \"best\" model -- what metric do you want to use here?\n",
        "\n",
        "* As a note, there will be n-grams that show up in the evaluation and training sets that don't show up in the training data, you will have to be able to account for this (of course, ignoring is acceptable) but your code shouldn't fail\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5sC6wBUTJPG",
        "outputId": "79ca8359-5ef6-4860-863a-12e983669358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "positive_raw_test = !ls -1 -d aclImdb/test/pos/*\n",
        "negative_raw_test = !ls -1 -d aclImdb/test/neg/*\n",
        "\n",
        "positive_eval = positive_raw_test[:len(positive_raw_test)//4]\n",
        "negative_eval = negative_raw_test[:len(negative_raw_test)//4]\n",
        "positive_test = positive_raw_test[len(positive_raw_test)//4:]\n",
        "negative_test = negative_raw_test[len(negative_raw_test)//4:]\n",
        "\n",
        "\n",
        "print(len(positive_eval))\n",
        "print(len(negative_eval))\n",
        "print(len(positive_test))\n",
        "print(len(negative_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3125\n",
            "3125\n",
            "9375\n",
            "9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QKSuebJTPZP",
        "outputId": "7dbdedf3-5c1f-43ee-8694-ee720808fc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_correct = 0\n",
        "n_samples = 0\n",
        "n_test = 1\n",
        "for reviews_test in negative_reviews:\n",
        "  row_data_test = []\n",
        "  gram_test = get_n_grams(reviews_test, n)\n",
        "  for i in range(len(vocabulary)):\n",
        "    temp_list_test = []\n",
        "    for j in range(n):\n",
        "      temp_list_test.append(vocabulary[i])\n",
        "    cmp_tuple_test = tuple(temp_list_test)\n",
        "    if cmp_tuple_test in gram_test.keys():\n",
        "      row_data_test.append(gram_test[cmp_tuple_test])\n",
        "    else:\n",
        "      row_data_test.append(0)\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    test = torch.FloatTensor(row_data_test).to(device)\n",
        "  outputs_test = linear_model(test)\n",
        "  print(outputs_test)\n",
        "  _, predictions = torch.max(outputs_test, 0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3983], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.4392], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5049], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6822], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1739], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3390], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6165], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9546], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6699], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2581], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0071], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9599], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4394], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4215], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8162], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3522], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3490], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6701], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2338], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6076], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4387], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.0465], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6434], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6350], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5149], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.3691], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7010], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7130], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8717], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8156], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5156], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1432], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0969], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6044], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5189], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9912], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6954], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2189], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0246], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5080], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5235], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4389], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4599], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7532], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6692], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7465], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.9349], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8957], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6582], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4204], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3636], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7705], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4748], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5051], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.0541], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3669], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4931], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7454], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4630], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5521], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6042], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5072], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2317], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6746], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.3624], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5205], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3926], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3699], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4339], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.9539], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0768], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5911], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4955], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2945], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5154], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.9069], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5657], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1583], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2670], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9295], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6801], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8626], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7276], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2479], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6602], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9055], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3979], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4193], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2345], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5836], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4754], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5555], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5432], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2519], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6722], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4150], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3067], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3387], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0596], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8878], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5474], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6175], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9350], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8171], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3895], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0817], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6679], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4223], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7395], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5052], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7246], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5022], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1341], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9889], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8035], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0754], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1517], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3908], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9646], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8878], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9585], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0127], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9169], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3749], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7222], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5823], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6772], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6845], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4026], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9123], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1890], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5078], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7551], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5229], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2000], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5191], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3229], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6707], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6141], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4296], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5151], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2637], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0720], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0809], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4465], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7348], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0766], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6264], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7915], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6766], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5650], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6034], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6797], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6034], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4389], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0028], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.0833], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4618], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5361], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6596], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3583], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8221], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6276], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.3060], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9775], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5172], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0859], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4815], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4144], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7133], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5136], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1261], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5590], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7226], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6473], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.2408], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1890], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6924], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7983], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5172], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3893], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8297], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3852], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0212], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3864], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3675], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9058], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1015], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6674], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7442], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6528], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5453], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5442], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9977], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.3286], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3441], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5091], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4658], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4658], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4607], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5514], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4493], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6820], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4444], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5495], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6921], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2590], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9126], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5482], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4250], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1388], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2134], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4674], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8605], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7078], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6300], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5142], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2540], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2615], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3473], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1634], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3748], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1771], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5138], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3473], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7113], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7258], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6707], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5963], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8727], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7218], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3986], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3450], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8106], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2864], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1622], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5435], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5370], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6689], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2096], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7670], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1325], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7407], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4837], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.9684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5516], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6331], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5641], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0497], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6204], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9574], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6350], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5074], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5913], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3458], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3902], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6421], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8791], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4650], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4257], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1572], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5269], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4829], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3574], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5421], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6316], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9122], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0772], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7253], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7237], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4328], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8915], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3630], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7108], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6957], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3266], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4569], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2368], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5884], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3280], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1750], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1310], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4578], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5288], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4410], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6758], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9389], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7642], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2223], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6879], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3581], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6910], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6504], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3392], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5555], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4739], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5321], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1650], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0898], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0241], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0890], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5045], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4147], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6384], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6479], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8878], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6363], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6602], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3137], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6265], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3056], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.0064], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6413], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.1537], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5660], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4030], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4512], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6426], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4330], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4854], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4278], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4691], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9134], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4255], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3741], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6525], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.9051], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3674], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4063], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4781], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5030], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8145], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6861], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2320], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8524], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7602], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6907], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4813], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8917], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5819], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8940], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5449], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6078], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0608], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8761], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4961], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9118], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6118], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0099], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3530], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9722], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7136], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5033], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0482], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7664], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6866], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4582], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0524], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5380], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4577], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6165], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3724], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6083], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1495], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5502], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7789], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3647], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3755], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3346], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6341], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3449], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2732], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5343], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6846], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3539], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7064], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6256], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2459], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4030], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8781], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6100], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5322], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3265], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9170], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8129], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.0295], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6081], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4439], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2415], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9486], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9262], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3606], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4916], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5023], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8704], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8158], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8859], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6386], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5684], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4456], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2811], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4570], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8173], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6916], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4917], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9184], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6018], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9322], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2533], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6381], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4686], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3974], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9894], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2136], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6409], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2840], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4307], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9743], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2871], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6702], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4873], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1838], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7964], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8480], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6449], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6270], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1618], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8286], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3921], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7261], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3923], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5032], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7596], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3454], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9225], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.0784], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4013], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3167], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5026], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5675], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7851], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4299], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7945], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2450], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3349], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5363], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3333], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7019], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6144], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5663], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8006], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7497], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6161], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2354], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5239], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6402], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1417], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5383], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2114], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3772], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5158], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8203], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1064], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3932], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7951], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3949], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6854], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7139], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3327], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5877], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5558], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5472], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.8240], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6712], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4802], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4163], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6833], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8754], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3669], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2544], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2637], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4915], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4642], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7922], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.3801], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6362], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5252], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6328], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8396], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.2513], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7044], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2625], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7822], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([3.4427], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([2.4627], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6370], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9779], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.1589], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5472], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7033], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.4091], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6151], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9692], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5538], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.9107], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3786], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.1274], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4590], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.3036], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2210], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8751], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7253], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5414], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.5129], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6432], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5315], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5947], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5369], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.7093], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4433], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6759], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7408], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2073], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2993], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.7566], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.2605], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4276], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([1.6689], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.6421], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4290], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.8298], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.4616], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-ebb5eb84e7b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtemp_list_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mtemp_list_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcmp_tuple_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_list_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VpPC8pGUrUE"
      },
      "source": [
        "## Bonus: Augment with unsupervised data\n",
        "* The dataset comes with more unsupervised data than supervised -- come up with a way to augment your training set with the unsupervised data, such that your model performance improves (to do this comparison keep model architecture the same, and compare the augmented data model vs the original on the evaluation set)"
      ]
    }
  ]
}